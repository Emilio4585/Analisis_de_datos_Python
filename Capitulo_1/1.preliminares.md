---
title: "1.Preliminares"
tags: ""
---

# 1.1 ¿De qué trata este libro?

Este libro se ocupa de los aspectos prácticos de la manipulación, el procesamiento, la limpieza y el procesamiento de datos en Python. Mi objetivo es ofrecer una guía de las partes del lenguaje de programación Python y su ecosistema de bibliotecas orientadas a datos y herramientas que lo equiparán para convertirse en un analista de datos eficaz. Si bien "análisis de datos" está en el título del libro, la atención se centra específicamente en la programación, las bibliotecas y las herramientas de Python, en contraposición a la metodología de análisis de datos. Esta es la programación de Python que necesita para el análisis de datos.

## ¿Qué tipo de datos?

Cuando digo "datos", ¿a qué me refiero exactamente? El enfoque principal está en los datos estructurados, un término deliberadamente vago que abarca muchas formas comunes diferentes de datos, como:

-   Datos tabulares o similares a una hoja de cálculo en los que cada columna puede ser de un tipo diferente (cadena, numérico, fecha u otro). Esto incluye la mayoría de los tipos de datos que se almacenan comúnmente en bases de datos relacionales o archivos de texto delimitados por comas o tabuladores.
-   Arreglos multidimensionales (matrices).
-   Varias tablas de datos interrelacionadas por columnas de clave (lo que serían claves primarias o externas para un usuario de SQL).
-   Series de tiempo espaciadas de manera uniforme o desigual.

Esta no es de ninguna manera una lista completa. Aunque no siempre sea obvio, un gran porcentaje de conjuntos de datos se puede transformar en una forma estructurada que sea más adecuada para el análisis y el modelado. De lo contrario, es posible extraer características de un conjunto de datos en una forma estructurada. Por ejemplo, una colección de artículos de noticias podría procesarse en una tabla de frecuencia de palabras, que luego podría usarse para realizar análisis de sentimientos.

La mayoría de los usuarios de programas de hojas de cálculo como Microsoft Excel, quizás la herramienta de análisis de datos más utilizada en el mundo, no serán ajenos a este tipo de datos.

# 1.2 ¿Por qué Python para el análisis de datos?

Para muchas personas, el lenguaje de programación Python tiene un gran atractivo. Desde su primera aparición en 1991, Python se ha convertido en uno de los lenguajes de programación interpretados más populares, junto con Perl, Ruby y otros. Python y Ruby se han vuelto especialmente populares desde 2005 aproximadamente para crear sitios web utilizando sus numerosos marcos web, como Rails (Ruby) y Django (Python). Estos lenguajes a menudo se denominan lenguajes de scripting, ya que se pueden utilizar para escribir rápidamente pequeños programas o scripts para automatizar otras tareas. No me gusta el término "lenguaje de secuencias de comandos", ya que tiene la connotación de que no se pueden utilizar para crear software serio. Entre los lenguajes interpretados, por diversas razones históricas y culturales, Python ha desarrollado una gran y activa comunidad de análisis de datos e informática científica. En los últimos 10 años, Python ha pasado de ser un lenguaje informático científico de vanguardia o "bajo su propio riesgo" a uno de los lenguajes más importantes para la ciencia de datos, el aprendizaje automático y el desarrollo de software en general en la academia y la industria.

Para el análisis de datos y la computación interactiva y la visualización de datos, Python inevitablemente establecerá comparaciones con otros lenguajes y herramientas de programación comercial y de código abierto de amplio uso, como R, MATLAB, SAS, Stata y otros. En los últimos años, el soporte mejorado de Python para bibliotecas (como pandas y scikit-learn) lo ha convertido en una opción popular para tareas de análisis de datos. Combinado con la fortaleza general de Python para la ingeniería de software de propósito general, es una excelente opción como lenguaje principal para crear aplicaciones de datos.

## Python como pegamento

Parte del éxito de Python en la informática científica es la facilidad de integrar código C, C ++ y FORTRAN. La mayoría de los entornos informáticos modernos comparten un conjunto similar de bibliotecas FORTRAN y C heredadas para realizar álgebra lineal, optimización, integración, transformaciones rápidas de Fourier y otros algoritmos similares. La misma historia ha sido válida para muchas empresas y laboratorios nacionales que han utilizado Python para unir el valor de décadas de software heredado.

Muchos programas constan de pequeñas porciones de código donde se pasa la mayor parte del tiempo, con grandes cantidades de "código adhesivo" que no se ejecuta con frecuencia. En muchos casos, el tiempo de ejecución del código de cola es insignificante; El esfuerzo se invierte más fructíferamente en optimizar los cuellos de botella computacionales, a veces moviendo el código a un lenguaje de nivel inferior como C.

## Resolviendo el problema de los "dos idiomas"

En muchas organizaciones, es común investigar, crear prototipos y probar nuevas ideas utilizando un lenguaje informático más especializado como SAS o R y luego transferir esas ideas para que formen parte de un sistema de producción más grande escrito en, por ejemplo, Java, C # o C ++. Lo que la gente encuentra cada vez más es que Python es un lenguaje adecuado no solo para investigar y crear prototipos, sino también para construir sistemas de producción. ¿Por qué mantener dos entornos de desarrollo cuando uno es suficiente? Creo que cada vez más empresas seguirán este camino, ya que a menudo hay importantes beneficios organizativos al tener tanto investigadores como ingenieros de software utilizando el mismo conjunto de herramientas de programación.

## ¿Por qué no Python?

Si bien Python es un entorno excelente para crear muchos tipos de aplicaciones analíticas y sistemas de propósito general, hay una serie de usos para los que Python puede ser menos adecuado.

Como Python es un lenguaje de programación interpretado, en general, la mayoría del código Python se ejecutará sustancialmente más lento que el código escrito en un lenguaje compilado como Java o C ++. Dado que el tiempo del programador suele ser más valioso que el tiempo de la CPU, muchos están felices de hacer esta compensación. Sin embargo, en una aplicación con una latencia muy baja o requisitos exigentes de utilización de recursos (por ejemplo, un sistema de negociación de alta frecuencia), el tiempo dedicado a la programación en un lenguaje de menor nivel (pero también de menor productividad) como C ++ para lograr el máximo rendimiento posible podría ser un tiempo bien gastado.

Python puede ser un lenguaje desafiante para crear aplicaciones multiproceso altamente concurrentes, en particular aplicaciones con muchos subprocesos vinculados a la CPU. La razón de esto es que tiene lo que se conoce como bloqueo de intérprete global (GIL), un mecanismo que evita que el intérprete ejecute más de una instrucción de Python a la vez.
Las razones técnicas por las que existe el GIL están más allá del alcance de este libro. Si bien es cierto que en muchas aplicaciones de procesamiento de big data, es posible que se requiera un grupo de computadoras para procesar un conjunto de datos en un período de tiempo razonable, todavía hay situaciones en las que es deseable un sistema multiproceso de un solo proceso.

Esto no quiere decir que Python no pueda ejecutar código paralelo verdaderamente multiproceso. Las extensiones de Python C que usan subprocesos múltiples nativos (en C o C ++) pueden ejecutar código en paralelo sin verse afectadas por GIL, siempre que no necesiten interactuar regularmente con objetos de Python.

# 1.3 Bibliotecas Python esenciales

Para aquellos que están menos familiarizados con el ecosistema de datos de Python y las bibliotecas utilizadas a lo largo del libro, daré una breve descripción general de algunas de ellas.

## NumPy

**NumPy**, abreviatura de Numerical Python, ha sido durante mucho tiempo una piedra angular de la computación numérica en Python. Proporciona las estructuras de datos, los algoritmos y el pegamento de biblioteca necesarios para la mayoría de las aplicaciones científicas que involucran datos numéricos en Python. NumPy contiene, entre otras cosas:

-   Un objeto de matriz multidimensional rápido y eficiente ndarray
-   Funciones para realizar cálculos de elementos con matrices o matemáticas
    operaciones cal entre matrices
-   Herramientas para leer y escribir conjuntos de datos basados en matrices en el disco
-   Operaciones de álgebra lineal, transformada de Fourier y generación de números aleatorios
-   Una API C madura para permitir que las extensiones de Python y el código nativo C o C ++ accedan Estructuras de datos e instalaciones computacionales de NumPy

Más allá de las capacidades de procesamiento rápido de matrices que NumPy agrega a Python, uno de sus usos principales en el análisis de datos es como contenedor para que los datos se pasen entre algoritmos y bibliotecas. Para datos numéricos, las matrices NumPy son más eficientes para almacenar y manipular datos que las otras estructuras de datos integradas de Python. Además, bibliotecas escrito en un lenguaje de nivel inferior, como C o Fortran, puede operar sobre los datos almacenados en una matriz NumPy sin copiar datos en alguna otra representación de memoria. Por lo tanto, muchas herramientas de computación numérica para Python asumen matrices NumPy como una estructura de datos primaria o bien apuntan a una interoperabilidad perfecta con NumPy.

## pandas

** pandas ** proporciona estructuras de datos de alto nivel y funciones diseñadas para que el trabajo con datos estructurados o tabulares sea rápido, fácil y expresivo. Desde su aparición en 2010, ha ayudado a que Python sea un entorno de análisis de datos potente y productivo. Los objetos principales en pandas que se utilizarán en este libro son el DataFrame, una estructura de datos tabular, orientada a columnas con etiquetas de fila y columna, y la Serie, un objeto de matriz etiquetado unidimensional.

pandas combina las ideas de computación de matrices de alto rendimiento de NumPy con las capacidades flexibles de manipulación de datos de hojas de cálculo y bases de datos relacionales (como SQL). Proporciona una funcionalidad de indexación sofisticada para que sea fácil remodelar, cortar y cortar, realizar agregaciones y seleccionar subconjuntos de datos. Dado que la manipulación, preparación y limpieza de datos es una habilidad tan importante en el análisis de datos, los pandas son uno de los enfoques principales de este libro.

Como antecedentes, comencé a construir pandas a principios de 2008 durante mi mandato en AQR Capital Management, una empresa de gestión de inversiones cuantitativas. En ese momento, tenía un conjunto distinto de requisitos que no estaban bien abordados por ninguna herramienta a mi disposición:

-   Estructuras de datos con ejes etiquetados que admiten la alineación de datos automática o explícita
    -   > esto evita errores comunes resultantes de datos desalineados y trabajar con datos indexados de manera diferente provenientes de diferentes fuentes
-   Funcionalidad de serie temporal integrada
-   Las mismas estructuras de datos manejan datos de series temporales y datos que no son de series temporales
-   Operaciones aritméticas y reducciones que conservan metadatos
-   Manejo flexible de datos faltantes
-   Fusionar y otras operaciones relacionales que se encuentran en bases de datos populares (basadas en SQL, por ejemplo)

Quería poder hacer todas estas cosas en un solo lugar, preferiblemente en un lenguaje adecuado para el desarrollo de software de propósito general. Python era un buen lenguaje candidato para esto, pero en ese momento no había un conjunto integrado de estructuras de datos y herramientas que proporcionaran esta funcionalidad. Como resultado de haber sido construido inicialmente para resolver problemas financieros y de análisis de negocios, pandas presenta funciones y herramientas de series temporales especialmente profundas, muy adecuadas para trabajar con datos indexados en el tiempo generados por procesos comerciales.

Para los usuarios del lenguaje R para la computación estadística, el nombre del DataFrame les resultará familiar, ya que el objeto recibió el nombre del objeto R data.frame similar. A diferencia de Python, los marcos de datos están integrados en el lenguaje de programación R y su biblioteca estándar. Como resultado, muchas de las características que se encuentran en pandas suelen ser parte de la implementación del núcleo de R o se proporcionan mediante paquetes complementarios.
The pandas name itself is derived from panel data, an econometrics term for multidi‐
mensional structured datasets, and a play on the phrase Python data analysis itself.

## matplotlib

** matplotlib ** es la biblioteca de Python más popular para producir gráficos y otras visualizaciones de datos bidimensionales. Fue creado originalmente por John D. Hunter y ahora lo mantiene un gran equipo de desarrolladores. Está diseñado para crear parcelas aptas para publicación. Si bien hay otras bibliotecas de visualización disponibles para los programadores de Python, matplotlib es la más utilizada y, como tal, tiene una buena integración en general con el resto del ecosistema. Creo que es una opción segura como herramienta de visualización predeterminada.

## IPython and Jupyter

The IPython project began in 2001 as Fernando Pérez’s side project to make a better interactive Python interpreter. In the subsequent 16 years it has become one of the most important tools in the modern Python data stack. While it does not provide any computational or data analytical tools by itself, IPython is designed from the ground
up to maximize your productivity in both interactive computing and software development. It encourages an execute-explore workflow instead of the typical edit-compile-run workflow of many other programming languages. It also provides easy access to your operating system’s shell and filesystem. Since much of data analysis coding involves exploration, trial and error, and iteration, IPython can help you get the job done faster.

En 2014, Fernando y el equipo de IPython anunciaron el proyecto Jupyter, una iniciativa más amplia para diseñar herramientas informáticas interactivas independientes del lenguaje. El portátil web IPython se convirtió en el portátil Jupyter, con soporte ahora para más de 40 lenguajes de programación. El sistema IPython ahora se puede usar como un kernel (un modo de lenguaje de programación) para usar Python con Jupyter.

El propio IPython se ha convertido en un componente del proyecto de código abierto Jupyter, mucho más amplio, que proporciona un entorno productivo para la informática interactiva y exploratoria. Su "modo" más antiguo y simple es como un shell de Python mejorado diseñado para acelerar la escritura, prueba y depuración de código Python. También puede utilizar el sistema IPython a través de Jupyter Notebook, un “cuaderno” de código interactivo basado en la web que ofrece soporte para docenas de lenguajes de programación. El shell de IPython y los cuadernos de Jupyter son especialmente útiles para la exploración y visualización de datos.

El sistema de libretas de Jupyter también le permite crear contenido en Markdown y HTML, lo que le proporciona un medio para crear documentos enriquecidos con código y texto. Otros lenguajes de programación también han implementado kernels para Jupyter para permitirle utilizar lenguajes distintos de Python en Jupyter.

Para mí, personalmente, IPython suele estar involucrado en la mayoría de mi trabajo en Python, incluida la ejecución, depuración y prueba de código.

En los materiales del libro adjunto, encontrará cuadernos de Jupyter que contienen todos los ejemplos de código de cada capítulo.

## SciPy

SciPy es una colección de paquetes que abordan una serie de diferentes dominios de problemas estándar en la informática científica. Aquí hay una muestra de los paquetes incluidos:

-   _scipy.integrate_
    -   Rutinas de integración numérica y solucionadores de ecuaciones diferenciales

-   _scipy.linalg_
    -   Rutinas de álgebra lineal y descomposiciones matriciales que se extienden más allá de las proporcionadas en _numpy.linalg_

-   _scipy.optimize_
    -   Optimizadores de funciones (minimizadores) y algoritmos de búsqueda de raíces

-   _scipy.signal_
    -   Herramientas de procesamiento de señales

-   _scipy.sparse_
    -   Matrices dispersas y solucionadores de sistemas lineales dispersos

-   _scipy.special_
    -   Envuelva **SPECFUN**, una biblioteca de Fortran que implementa muchas funciones matemáticas comunes, como la función gamma

-   _scipy.stats_
    -   Distribuciones de probabilidad estándar continuas y discretas (funciones de densidad, muestreadores, funciones de distribución continua), varias pruebas estadísticas y estadísticas más descriptivas

Juntos, NumPy y SciPy forman una base computacional razonablemente completa y madura para muchas aplicaciones informáticas científicas tradicionales.

## scikit-learn

Desde el inicio del proyecto en 2010, **scikit-learn** se ha convertido en el principal kit de herramientas de aprendizaje automático de uso general para programadores de Python. En solo siete años, ha tenido más de 1.500 colaboradores de todo el mundo. Incluye submódulos para modelos como:

-   Clasificación: SVM, vecinos más cercanos, bosque aleatorio, regresión logística, etc.
-   Regresión: Lazo, regresión de crestas, etc.
-   Agrupación: k-medias, agrupación espectral, etc.
-   Reducción de dimensionalidad: PCA, selección de características, factorización matricial, etc.
-   Selección de modelo: búsqueda de cuadrícula, validación cruzada, métricas
-   Preprocesamiento: extracción de características, normalización

Junto con pandas, statsmodels e IPython, scikit-learn ha sido fundamental para permitir que Python sea un lenguaje de programación de ciencia de datos productivo. Si bien no podré incluir una guía completa de scikit-learn en este libro, daré una breve introducción a algunos de sus modelos y cómo usarlos con las otras herramientas presentadas en el libro.

## statsmodels

**statsmodels** es un paquete de análisis estadístico que fue sembrado por el trabajo del profesor de estadística de la Universidad de Stanford Jonathan Taylor, quien implementó una serie de modelos de análisis de regresión populares en el lenguaje de programación R. Skipper Seabold y Josef Perktold crearon formalmente el nuevo proyecto statsmodels en 2010 y desde entonces han hecho crecer el proyecto a una masa crítica de usuarios y contribuyentes comprometidos. Nathaniel Smith desarrolló el proyecto Patsy, que proporciona una fórmula o marco de especificación de modelo para modelos estadísticos inspirados en el sistema de fórmulas de R.

En comparación con scikit-learn, statsmodels contiene algoritmos para estadísticas y econometría clásicas (principalmente frecuentistas). Esto incluye submódulos como:

-   Modelos de regresión: Regresión lineal, modelos lineales generalizados, modelos lineales robustos, modelos lineales de efectos mixtos, etc.
-   Análisis de varianza (ANOVA)
-   Análisis de series de tiempo: AR, ARMA, ARIMA, VAR y otros modelos
-   Métodos no paramétricos: estimación de densidad de kernel, regresión de kernel
-   Visualización de resultados del modelo estadístico

statsmodels se centra más en la inferencia estadística, proporcionando estimaciones de incertidumbre y valores p para los parámetros. scikit-learn, por el contrario, se centra más en la predicción.

Al igual que con scikit-learn, daré una breve introducción a statsmodels y cómo usarlo con NumPy y pandas.

# 1.4 Instalación y configuración

Dado que todo el mundo usa Python para diferentes aplicaciones, no existe una solución única para configurar Python y los paquetes complementarios necesarios. Muchos lectores no tendrán un entorno de desarrollo Python completo adecuado para seguir este libro, así que aquí daré instrucciones detalladas para configurar cada sistema operativo. Recomiendo usar la distribución gratuita de Anaconda. En el momento de escribir este artículo, Anaconda se ofrece en las formas Python 2.7 y 3.6, aunque esto podría cambiar en algún momento en el futuro. Este libro utiliza Python 3.6 y le animo a que utilice Python 3.6 o superior.

## Windows

Para comenzar con Windows, descargue el instalador de Anaconda. Recomiendo seguir las instrucciones de instalación para Windows disponibles en la página de descarga de Anaconda, que pueden haber cambiado entre el momento en que se publicó este libro y el momento en que lo lee.

Ahora, verifiquemos que las cosas estén configuradas correctamente. Para abrir la aplicación Símbolo del sistema (también conocida como cmd.exe), haga clic con el botón derecho en el menú Inicio y seleccione Símbolo del sistema. Intente iniciar el intérprete de Python escribiendo python. Debería ver un mensaje que coincide con la versión de Anaconda que instaló:

```sh
C:\Users\wesm>python
Python 3.5.2 |Anaconda 4.1.1 (64-bit)| (default, Jul
 5 2016, 11:41:13)
[MSC v.1900 64 bit (AMD64)] on win32
>>>
```

Para salir del shell, presione Ctrl-D (en Linux o macOS), Ctrl-Z (en Windows), o escriba el comando `exit ()` y presione Enter.

## Apple (OS X, macOS)

Descargue el instalador de OS X Anaconda, que debería llamarse algo así como `Anaconda3-4.1.0-MacOSX-x86_64.pkg`. Haga doble clic en el archivo .pkg para ejecutar el instalador. Cuando se ejecuta el instalador, agrega automáticamente la ruta ejecutable de Anaconda a su archivo `.bash_profile`. Este se encuentra en `/Users/$USER/.bash_profile`.

Para verificar que todo está funcionando, intente iniciar `IPython` en el shell del sistema (abra la aplicación Terminal para obtener un símbolo del sistema):

```zsh
$ ipython
```

## GNU/Linux

Los detalles de Linux variarán un poco dependiendo de su versión de Linux, pero aquí doy detalles para distribuciones como Debian, Ubuntu, CentOS y Fedora. La configuración es similar a OS X con la excepción de cómo se instala Anaconda. El instalador es un script de shell que debe ejecutarse en la terminal. Dependiendo de si tiene un sistema de 32 bits o de 64 bits, deberá instalar el instalador x86 (32 bits) o x86_64 (64 bits). Luego tendrá un archivo llamado algo similar a `Anaconda3-4.1.0-Linux-x86_64.sh`. Para instalarlo, ejecute este script con bash:

```bash
$ bash Anaconda3-4.1.0-Linux-x86_64.sh
```

> Algunas distribuciones de Linux tienen versiones de todos los Python necesarios paquetes en sus administradores de paquetes y se pueden instalar usando un herramienta como apt. La configuración que se describe aquí usa Anaconda, ya que es tanto fácilmente reproducible en todas las distribuciones y más sencillo de actualizar
> paquetes a sus últimas versiones.

Después de aceptar la licencia, se le presentará la opción de dónde colocar los archivos de Anaconda. Recomiendo instalar los archivos en la ubicación predeterminada de su directorio personal, por ejemplo, `/ home / $ USER / anaconda` (con su nombre de usuario, naturalmente).

El instalador de Anaconda puede preguntarle si desea anteponer su directorio bin / a su variable `$ PATH`. Si tiene algún problema después de la instalación, puede hacerlo usted mismo modificando su `.bashrc` (o` .zshrc`, si está usando el shell zsh) con algo similar a:

```bash
export PATH=/home/$USER/anaconda/bin:$PATH
```

Después de hacer esto, puede iniciar un nuevo proceso de terminal o ejecutar su `.bashrc` nuevamente con la fuente` ~ / .bashrc`.

## Instalación o actualización de paquetes de Python

En algún momento mientras lee, es posible que desee instalar paquetes de Python adicionales que no están incluidos en la distribución de Anaconda. En general, estos se pueden instalar con el siguiente comando:

```bash
conda install package_name
```

Si esto no funciona, también puede instalar el paquete utilizando la herramienta de administración de paquetes pip:

```bash
pip install package_name
```

Puede actualizar los paquetes usando el comando de actualización conda:

```bash
conda update package_name
```

pip también admite actualizaciones usando la bandera --upgrade:

```bash
pip install --upgrade package_name
```

Tendrá varias oportunidades de probar estos comandos a lo largo del libro.

> Si bien puede usar tanto conda como pip para instalar paquetes,
> no debería intentar actualizar los paquetes de conda con pip, ya que hacerlo puede provocar problemas medioambientales. Cuando use Anaconda o Miniconda, es mejor intentar primero actualizar con conda.

## Python 2 and Python 3

La primera versión de la línea de intérpretes de Python 3.x se lanzó a finales de 2008. Incluía una serie de cambios que hacían incompatibles algunos códigos de Python 2.x previamente escritos. Debido a que habían pasado 17 años desde el primer lanzamiento de Python en 1991, se consideraba que la creación de un lanzamiento de "ruptura" de Python 3 era un bien mayor dadas las lecciones aprendidas durante ese tiempo.

En 2012, gran parte de la comunidad científica y de análisis de datos todavía usaba Python 2.x porque muchos paquetes no se habían hecho completamente compatibles con Python 3. Por tanto, la primera edición de este libro utilizó Python 2.7. Ahora, los usuarios son libres de elegir entre Python 2.xy 3.xy, en general, tienen soporte completo para bibliotecas con cualquiera de los dos tipos.

Sin embargo, Python 2.x llegará al final de su vida útil de desarrollo en 2020 (incluidos los parches de seguridad críticos), por lo que ya no es una buena idea comenzar nuevos proyectos en Python 2.7. Por lo tanto, este libro utiliza Python 3.6, una versión estable ampliamente implementada y bien soportada. Hemos comenzado a llamar a Python 2.x "Python heredado" y Python 3.x simplemente "Python". Yo te animo a que hagas lo mismo.

Este libro utiliza Python 3.6 como base. Su versión de Python puede ser más reciente que la 3.6, pero los ejemplos de código deben ser compatibles con versiones posteriores. Algunos ejemplos de código pueden funcionar de manera diferente o no funcionar en absoluto en Python 2.7.

## Entornos de desarrollo integrados (IDE) y editores de texto

Cuando me preguntan sobre mi entorno de desarrollo estándar, casi siempre digo "IPython más un editor de texto". Normalmente escribo un programa y pruebo y depuro iterativamente cada pieza en los cuadernos de IPython o Jupyter. También es útil poder jugar con los datos de forma interactiva y verificar visualmente que un conjunto particular de manipulaciones de datos está haciendo lo correcto. Las bibliotecas como pandas y NumPy están diseñadas para ser fáciles de usar en el shell.

Sin embargo, al crear software, algunos usuarios pueden preferir utilizar un IDE con más funciones en lugar de un editor de texto comparativamente primitivo como Emacs o Vim. Aquí hay algunos que puede explorar:

-   PyDev (gratis), un IDE construido sobre la plataforma Eclipse
-   PyCharm de JetBrains (basado en suscripción para usuarios comerciales, gratis para abrir
    desarrolladores de fuentes)
-   Python Tools para Visual Studio (para usuarios de Windows)
-   Spyder (gratis), un IDE que se envía actualmente con Anaconda
-   Komodo IDE (comercial)

Debido a la popularidad de Python, la mayoría de los editores de texto, como Atom y Sublime Text 2, tienen un excelente soporte para Python.

# 1.5 Comunidad y conferencias

Fuera de una búsqueda en Internet, las diversas listas de correo de Python científicas y relacionadas con datos son generalmente útiles y responden a preguntas. Algunos para echar un vistazo incluyen:

-   pydata: una lista de Google Group para preguntas relacionadas con Python para análisis de datos y pandas
-   pystatsmodels: para modelos de estadísticas o preguntas relacionadas con pandas
-   Lista de correo para scikit-learn ([scikit-learn@python.org](mailto:scikit-learn@python.org)) y aprendizaje automático en Python, generalmente
-   discusión numpy: para preguntas relacionadas con NumPy
-   scipy-user: para preguntas generales de ciencia ficción o Python científicas

Deliberadamente no publiqué URL para estos en caso de que cambien. Se pueden localizar fácilmente mediante una búsqueda en Internet.

Cada año se llevan a cabo muchas conferencias en todo el mundo para programadores de Python. Si desea conectarse con otros programadores de Python que comparten sus intereses, le animo a que explore asistir a uno, si es posible. Muchas conferencias tienen apoyo financiero disponible para aquellos que no pueden pagar la entrada o viajar a la conferencia. A continuación, presentamos algunos para considerar:

-   PyCon y EuroPython: las dos principales conferencias generales de Python en América del Norte y Europa, respectivamente
-   SciPy y EuroSciPy: conferencias orientadas a la informática científica en América del Norte y Europa, respectivamente
-   PyData: una serie mundial de conferencias regionales dirigidas a casos de uso de ciencia y análisis de datos
-   Conferencias PyCon internacionales y regionales (consulte <http://pycon.org> para obtener una lista completa)
